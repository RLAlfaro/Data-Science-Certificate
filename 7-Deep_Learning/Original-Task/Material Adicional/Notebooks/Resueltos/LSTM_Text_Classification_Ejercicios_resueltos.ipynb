{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-Text-Classification-Ejercicios_resueltos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6954425609f44a48ba67a5bac432f58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b0c169eb51a540878a5b3d5d3e85a712",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_42b7ca5b686446ae890f3085b6d48bd6",
              "IPY_MODEL_3d21327e450541f6a1a53070028cc13f"
            ]
          }
        },
        "b0c169eb51a540878a5b3d5d3e85a712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42b7ca5b686446ae890f3085b6d48bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b8432650e50d4b7ebe8332cc87ad5a35",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 60000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 60000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e3d7c61e35a48319976ad085d455367"
          }
        },
        "3d21327e450541f6a1a53070028cc13f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_785a6b102d1c4903bc8003ff250a053c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 60000/60000 [00:02&lt;00:00, 25529.16it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25459e5a18a64a08af6116a404395862"
          }
        },
        "b8432650e50d4b7ebe8332cc87ad5a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e3d7c61e35a48319976ad085d455367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "785a6b102d1c4903bc8003ff250a053c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25459e5a18a64a08af6116a404395862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NOabgNEKMm5"
      },
      "source": [
        "# Clasificación de texto utilizando LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdXDCK3v75ol"
      },
      "source": [
        "#Importamos nuestras librerias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l01ge_gCzXaC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b334909-f007-4692-a531-70c634779eef"
      },
      "source": [
        "#Descargamos los datos\n",
        "!curl -O http://srodriguez.me/Datasets/imdb.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 25.7M  100 25.7M    0     0  8485k      0  0:00:03  0:00:03 --:--:-- 8485k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFoTx4EVzdpM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efabe35e-80a1-4b9c-f290-7cd823a5d05b"
      },
      "source": [
        "#Descomprimimos los datos\n",
        "!unzip imdb.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  imdb.zip\n",
            "  inflating: IMDB Dataset.csv        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3inJdD8GKO0y"
      },
      "source": [
        "# Carga de datos\n",
        "\n",
        "En este caso vamos a cargar los datos de IMDB, para clasificación de sentimiento "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G_hF3lazg2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f20057a0-585c-457d-ffd9-78eac267987b"
      },
      "source": [
        "#Generamos nuestro Dataframe, leyendo el archivo .csv\n",
        "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HljHmgyAzl-d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f201ded6-743f-451c-ddb0-8dd5d520a74d"
      },
      "source": [
        "# Mostramos los primero 5 elementos\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt-WYDkQzrxI"
      },
      "source": [
        "#Muestreamos 10.000 reviews en vez de procesar todo el conjunto de dato\n",
        "sub_df = df.sample(30000)\n",
        "sub_df.reset_index(drop=True,inplace=True) #Reiniciamos los indices de este nuevo df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOCb88TBzrz_"
      },
      "source": [
        "# Se transforma el texto de las etiquetas en valores numericos para el proceso de aprendizaje\n",
        "sub_df['sentiment'] = sub_df['sentiment'].map({'positive':1,'negative':0})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXWNgpkjzvBO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "6d011bb5-fc4b-4836-c40e-d2bd0933f4bd"
      },
      "source": [
        "#Vemos el primer review del nuevo set de datos\n",
        "sub_df.review[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'think round applause order whoever pieced together trailer rogue pictures\\' latest release, \\'the return\\'. myself, along everyone else duped believing fact horror film. contrary though, actually supernatural thriller. bad least bit thrilling.<br /><br />\\'the return\\' stars sarah michelle gellar joanna mills, young woman personal problems since age eleven. age began haunting visions depicting murder woman never met. texas business trip, led visions murdered woman\\'s hometown, la salle. comes face face another person frequently appeared visions. man name terry stahl, played peter o\\'brien. joanna desperate search answers. search could end result murder.<br /><br />i really know begin folks. mention first? atrocious acting, hideous directing, terribly bland story? matter one choose point behind same: simply suck. adam sussman\\'s screenplay downright moronic. interesting. compelling. plain unpleasant. kept waiting something jumpstart \"film\" (i\\'ve placed quotations around film believe \\'the return\\' deserves called actual film due foulness.) least give slight chance hope, nothing ever happened. left unbearable cold freeze. even stellar performances actors could saved disaster. course probably knew read script agreeing \"film\". assume acting awful. least that\\'s i\\'m choosing believe. really hope cast pride performances. need immediate medical attention do.<br /><br />now directing unmistakably bad, can\\'t quite crucify asif kapadia entirely. (well could, since i\\'m nice guy.) look \\'the return\\' test kapadia know, first full-length feature \"film\". he\\'s getting foot door still learning. next time around, well next time, hopefully improved vastly. thing able accomplish almost completely duplicating visual style marcus nispel\\'s 2003 re-make \\'the texas chainsaw massacre\\'. that\\'s nice \"film\" given that, unfortunately still receiving kudos that. copying someone else\\'s work something consider praise worthy. (even film much enjoyed.)<br /><br />i think jim sonzero\\'s american re-make \\'pulse\\' fork title worst film year \\'the return\\'. beyond question deserving title almost every imaginable way. doubt make small, mean small, profit. matter though, surpass even parallel fluke success gellar\\'s previous acting effort, \\'the grudge\\'. note, there\\'s one last thing i\\'d like add. honestly say never embarrassed seen leaving theater auditorium seeing \\'the return\\'. something never wish experience again, along \"film\" itself.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51UV58VqVbjK",
        "outputId": "ddbb993d-e918-4f62-c26e-ead5b20f85b7"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emFA1PQpUt9i"
      },
      "source": [
        "# Cleaning the texts\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "\n",
        "\"\"\"review=[ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "review=' '.join(review)\n",
        "corpus.append(review)\"\"\"\n",
        "\n",
        "stopwords_set = set(stopwords.words('english'))\n",
        "\n",
        "sub_df['review'] = sub_df['review'].apply(lambda x: \" \".join([word for word in x.lower().split(\" \") if not word in stopwords_set]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV82LhmTz1tb"
      },
      "source": [
        "#Importamos la funcion para hacer separacion de los distintos conjuntos de entrenamiento\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unmwI-vgzr2e"
      },
      "source": [
        "#Separamos un 30% de datos para test\n",
        "temp_df, test_df = train_test_split(sub_df,test_size=0.3,random_state=42)\n",
        "#y de training, sacamos un 10% para validación\n",
        "train_df, val_df = train_test_split(temp_df,test_size=0.1,random_state=42)\n",
        "\n",
        "train_df.reset_index(drop=True,inplace=True)\n",
        "val_df.reset_index(drop=True,inplace=True)\n",
        "test_df.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsF9anNSz4ws"
      },
      "source": [
        "max_features = 60000  # Considerar las primeras 20000 palabras para generar un diccionario\n",
        "maxlen = 200  # Considerar las primeras 200 palabras de cada review\n",
        "\n",
        "#Generamos nuestro tokenizador, el cual nos va a permitir generar nuestro diccionario\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words=max_features, oov_token='<unk>', )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-9-GoWYz4y5"
      },
      "source": [
        "#Construimos el vocabulario\n",
        "tokenizer.fit_on_texts(train_df['review'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qU7Si9GI1MTO",
        "outputId": "68c27d0d-4d53-40cd-e083-fa6064939c28"
      },
      "source": [
        "#Vemos que palabra corresponde al indice numero 2\n",
        "tokenizer.index_word[3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'movie'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCslOz-s1NeI",
        "outputId": "0408ccdc-1c37-4757-c64d-acc9e2a42d2f"
      },
      "source": [
        "#Vemos que indice que corresponde la palabra 'the'\n",
        "tokenizer.word_index['red']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D8ru_YE0i_A"
      },
      "source": [
        "#Generamos las secuencias al transformar de texto a valores numericos\n",
        "secuencias = tokenizer.texts_to_sequences(train_df['review'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrmlFcEx2QpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f806b18c-7e5c-4c03-fc9e-e4044c7498f9"
      },
      "source": [
        "#Fijamos las secuencias en un largo especifico, añadiendo los token de padding '<pad>'\n",
        "secuencias_padded = keras.preprocessing.sequence.pad_sequences(secuencias,maxlen= maxlen)\n",
        "secuencias_padded.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18900, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4hi9o0060C2",
        "outputId": "393d9a29-a188-483f-9c90-314ccaf333de"
      },
      "source": [
        "maxlen"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQW05DsA3K-5"
      },
      "source": [
        "# Transformamos el texto a secuencia para los conjuntos de validacion y testing\n",
        "val_seq = tokenizer.texts_to_sequences(val_df['review'])\n",
        "val_seq_padded = keras.preprocessing.sequence.pad_sequences(val_seq,maxlen= maxlen)\n",
        "\n",
        "test_seq = tokenizer.texts_to_sequences(test_df['review'])\n",
        "test_seq_padded = keras.preprocessing.sequence.pad_sequences(test_seq,maxlen= maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBz0bZpr1dYn"
      },
      "source": [
        "#Generamos nuestras entradas para la red\n",
        "X_train = secuencias_padded\n",
        "y_train =train_df['sentiment']\n",
        "\n",
        "X_val = val_seq_padded\n",
        "y_val = val_df['sentiment']\n",
        "\n",
        "X_test = test_seq_padded\n",
        "y_test = test_df['sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zEwlwaZ8ULH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "342c977f-b455-4c9d-a499-bc751bd685b4"
      },
      "source": [
        "#Capa de entrada, la cual recibira los arreglos de interos (indices del vocabulario)\n",
        "inputs = keras.Input(shape=(maxlen,), dtype=\"int32\")\n",
        "# Transformamos cada indice, en su vector de palabras correspondiente\n",
        "x = layers.Embedding(max_features + 1, 128)(inputs)\n",
        "#Añadimos una capa de LSTM\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "\n",
        "# Añadimos la capa de salida, 1 neurona de salida debido a que es clasificación binaria\n",
        "# Ademas, utilizamos la funcion de activación sigmoidea para que arroje la probabilidad\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "#Generamos el modelo\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary() # E imprimimos el modelo \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_8 (Embedding)      (None, 200, 128)          2560128   \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,659,073\n",
            "Trainable params: 2,659,073\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--hK_bIo8Ueq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n8JkBOO8UhS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f5caf08-a754-49cf-d6a0-c340ed9d47f4"
      },
      "source": [
        "#Compilamos el modelo, seleccionamos el optimizado, la funcion de perdida y la metrica de exactitud\n",
        "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "#Ajustamos el modelo, utilizando los conjuntos de entrenamiento y validamos con el conjunto de validación\n",
        "#Entrenamos por 5 \"Epocas\"\n",
        "model.fit(X_train, y_train, batch_size=16, epochs=2, validation_data=(X_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1182/1182 [==============================] - 52s 44ms/step - loss: 0.4300 - accuracy: 0.8019 - val_loss: 0.3646 - val_accuracy: 0.8367\n",
            "Epoch 2/2\n",
            "1182/1182 [==============================] - 52s 44ms/step - loss: 0.2423 - accuracy: 0.9055 - val_loss: 0.3454 - val_accuracy: 0.8633\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faceafca748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elpnuveo8Ujz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "644f82d8-c215-4d82-e3cc-d53812391489"
      },
      "source": [
        "#Realizamos la prediccion del modelo y vemos el output (Son probabilidades)\n",
        "y_pred = model.predict(X_test,batch_size=16,verbose=1)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "563/563 [==============================] - 4s 8ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9856192 ],\n",
              "       [0.30775046],\n",
              "       [0.99553776],\n",
              "       ...,\n",
              "       [0.02330089],\n",
              "       [0.14930056],\n",
              "       [0.9933368 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmZiCMT68UmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e800b63-259d-43fc-e6c6-959f35c1948e"
      },
      "source": [
        "#Transformamos la prediccion en valores binarios al preguntar por todos los valores\n",
        "# mayores o iguales a 0.5\n",
        "y_pred = y_pred >= 0.5\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       ...,\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h44xtWSW4pNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9cfc036-f923-4185-d74e-e04e3193a671"
      },
      "source": [
        "#Transformamos los valores binarios a '0' y '1' utilizando una representación de enteros\n",
        "y_pred = y_pred.astype(int)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [1],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkO8l2pR5W_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfb5b6c4-721a-42ac-eaa3-21d8b9b37c34"
      },
      "source": [
        "#Aplanamos el vector para que quede de forma unidimensional\n",
        "y_pred = y_pred.reshape(-1)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2-nIxKL4s3t"
      },
      "source": [
        "#Importamos la libreria de métricas de scikit-learn\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYPT23Sp5ALz"
      },
      "source": [
        "model.save(\"modelo.h5\") #Salvamos el modelo (o los pesos de este) para un futuro uso"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmQfFlWvXjDA"
      },
      "source": [
        "model.load_weights(\"modelo.h5\") #Con una arqutectura similar, rescatamos el modelo +"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlX4YfW75L1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eaa7d77-7da5-49e8-e748-3ea2cc020cfb"
      },
      "source": [
        "#Imprimimos los valores de prueba, solo por sanity check\n",
        "print(y_test.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v85niM3a42fF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed9f069-8f60-4923-c67a-a79e28b98fbb"
      },
      "source": [
        "#Imprimimos las metricas\n",
        "print(metrics.accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.869\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.85      0.87      4598\n",
            "           1       0.85      0.89      0.87      4402\n",
            "\n",
            "    accuracy                           0.87      9000\n",
            "   macro avg       0.87      0.87      0.87      9000\n",
            "weighted avg       0.87      0.87      0.87      9000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pf2NStmWdfw",
        "outputId": "1c876689-04ac-4f02-b502-e89622eab3c3"
      },
      "source": [
        "print(metrics.confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3925  673]\n",
            " [ 506 3896]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW8MGDeQ9Gei"
      },
      "source": [
        "# Utilizando vectores de palabras pre-entrenados\n",
        "\n",
        "https://github.com/RaRe-Technologies/gensim-data <- De aca podemos obtener modelos pre-entrenados soportados por la misma libreria de GenSim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RqSMFuP481V"
      },
      "source": [
        "import gensim.downloader as api\n",
        "#En este caso, vamos a utilizar los vectores entrenados en wikipedia mediante el algoritmo Globe\n",
        "#wv = api.load('glove-wiki-gigaword-300')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bctxLdnj-F30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddeb5aa1-f78e-49b9-b68c-3ff270cbf8bc"
      },
      "source": [
        "#Verificamos que la palabra 'the' exista y mostramos los primeros 10 valores\n",
        "wv['the'][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.04656  ,  0.21318  , -0.0074364, -0.45854  , -0.035639 ,\n",
              "        0.23643  , -0.28836  ,  0.21521  , -0.13486  , -1.6413   ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyg-UlNp8QAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cf29db8-a5a5-4d35-88b3-03b2e165f246"
      },
      "source": [
        "# Instanciamos una matriz incializada al azar con un vocabulario de max_features + 1\n",
        "# Esto ultimo es para considerar el vector asociado al token '<pad>'\n",
        "emb_matrix = np.random.rand(max_features + 1,300) #El largo de nuestro vector\n",
        "\n",
        "emb_matrix[0][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.61106771, 0.74995914, 0.63748152, 0.44308281, 0.5318564 ,\n",
              "       0.78282585, 0.66913958, 0.80441194, 0.24493687, 0.56856688])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H3DpuBK-UhW"
      },
      "source": [
        "#Importamos una libreria para hacer seguimiento del procesos de traspaso de embeddings\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NottHuW59UzW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "6954425609f44a48ba67a5bac432f58b",
            "b0c169eb51a540878a5b3d5d3e85a712",
            "42b7ca5b686446ae890f3085b6d48bd6",
            "3d21327e450541f6a1a53070028cc13f",
            "b8432650e50d4b7ebe8332cc87ad5a35",
            "5e3d7c61e35a48319976ad085d455367",
            "785a6b102d1c4903bc8003ff250a053c",
            "25459e5a18a64a08af6116a404395862"
          ]
        },
        "outputId": "851367a3-a5e0-4b07-e1ed-d9a7d3d07d10"
      },
      "source": [
        "#Iteramos por cada una de las palabras\n",
        "for i in tqdm(range(1, max_features + 1)):\n",
        "  #Obtenemos la palabra correspondiente al indice i\n",
        "  word = tokenizer.index_word[i]\n",
        "  if word in wv: #Preguntamos si la palabra esta en el modelo de vectores de palabra\n",
        "    emb_matrix[i] = wv[word] # Asignamos el valor a la fila al vector de palabra\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6954425609f44a48ba67a5bac432f58b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQCrj9jV-T2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb40c4ec-b1b2-49c8-b460-17b453eb3f93"
      },
      "source": [
        "#Comprobamos que el la matriz de embeddings populada, el indice 2 (para la palabra 'the') \n",
        "#corresponde al valor que vimos anteriormente\n",
        "emb_matrix[2:6,:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.40287   , -0.48699   ,  0.091598  , -0.071945  , -0.063545  ],\n",
              "       [-0.138     , -0.12203   ,  0.0054643 , -0.010215  ,  0.13134   ],\n",
              "       [-0.030351  , -0.17344999, -0.097576  , -0.20939   , -0.1964    ],\n",
              "       [-0.36756   ,  0.39500001, -0.27034   , -0.14816999, -0.026378  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOaQPDQ9-xBl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09780c6b-ba5e-47dd-e585-9878b8cf0b07"
      },
      "source": [
        "#Capa de entrada, la cual recibira los arreglos de interos (indices del vocabulario)\n",
        "inputs = keras.Input(shape=(maxlen,), dtype=\"int32\")\n",
        "# Transformamos cada indice, en su vector de palabras correspondiente\n",
        "# Pero esta vez, utilizando el parametro weights, inicializamos esta capa de vectores\n",
        "# Con los pesos extraidos del modelo pre-entrenado\n",
        "# Aparte, definimos que esta capa no sea entrenable, o sea que los valores de los pesos\n",
        "# No se vayan ajustando en cada iteración de entrenamiento\n",
        "x = layers.Embedding(max_features + 1, 300,weights=[emb_matrix], trainable=False)(inputs)\n",
        "#Añadimos una capa de LSTM\n",
        "x = layers.LSTM(64)(x)\n",
        "# Añadimos la capa de salida, 1 neurona de salida debido a que es clasificación binaria\n",
        "# Ademas, utilizamos la funcion de activación sigmoidea para que arroje la probabilidad\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "#Generamos el modelo\n",
        "model2 = keras.Model(inputs, outputs)\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_12 (Embedding)     (None, 200, 300)          18000300  \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 18,093,805\n",
            "Trainable params: 93,505\n",
            "Non-trainable params: 18,000,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5979lFwH_59H"
      },
      "source": [
        "#Evaluamos y obtenemos las metricas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZbXwckzARFF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "1db54199-adfe-4c57-97d7-8b95938105eb"
      },
      "source": [
        "model2.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model2.fit(X_train, y_train, batch_size=16, epochs=6, validation_data=(X_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "1182/1182 [==============================] - 12s 11ms/step - loss: 0.4460 - accuracy: 0.7923 - val_loss: 0.3489 - val_accuracy: 0.8452\n",
            "Epoch 2/6\n",
            "1182/1182 [==============================] - 12s 10ms/step - loss: 0.3290 - accuracy: 0.8649 - val_loss: 0.3161 - val_accuracy: 0.8590\n",
            "Epoch 3/6\n",
            "1182/1182 [==============================] - 12s 10ms/step - loss: 0.2725 - accuracy: 0.8898 - val_loss: 0.2969 - val_accuracy: 0.8738\n",
            "Epoch 4/6\n",
            "1182/1182 [==============================] - 12s 10ms/step - loss: 0.2281 - accuracy: 0.9053 - val_loss: 0.2943 - val_accuracy: 0.8800\n",
            "Epoch 5/6\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 0.1805 - accuracy: 0.9311 - val_loss: 0.2885 - val_accuracy: 0.8743\n",
            "Epoch 6/6\n",
            " 638/1182 [===============>..............] - ETA: 5s - loss: 0.1358 - accuracy: 0.9493"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-219-ec7b796a22c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVombM0UARFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b000fd8-c164-4064-89f6-f18dedc39240"
      },
      "source": [
        "y_pred = model2.predict(X_test,batch_size=16,verbose=1)\n",
        "y_pred = y_pred >= 0.5\n",
        "y_pred = y_pred.astype(np.int8).reshape(-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "563/563 [==============================] - 3s 5ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPpRpfsCARFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11ff17a6-3f06-4964-efca-8448107ad782"
      },
      "source": [
        "print(metrics.accuracy_score(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8842222222222222\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.90      0.89      4598\n",
            "           1       0.89      0.87      0.88      4402\n",
            "\n",
            "    accuracy                           0.88      9000\n",
            "   macro avg       0.88      0.88      0.88      9000\n",
            "weighted avg       0.88      0.88      0.88      9000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaLtTdQkQwQ6",
        "outputId": "35bccfe2-e484-4b29-dafc-c046957a0ddf"
      },
      "source": [
        "# Como modelar texto del usuario para hacer las pruebas\n",
        "\n",
        "\n",
        "texto_ejemplo = \"i love so much this movie\" # Recepcion de texto\n",
        "\n",
        "##\n",
        "# Preprocesamos (quitamos tildes, sacamos stopwords, dejamos todas las palabras)\n",
        "##\n",
        "\n",
        "ej_seq = tokenizer.texts_to_sequences([texto_ejemplo])\n",
        "ej_seq_padded = keras.preprocessing.sequence.pad_sequences(ej_seq,maxlen= maxlen)\n",
        "\n",
        "print(ej_seq)\n",
        "print(ej_seq_padded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[36, 41, 174, 17, 43, 3]]\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0  36  41 174  17\n",
            "   43   3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAKCrU96AWM9"
      },
      "source": [
        "model2.predict(ej_seq_padded)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2Q_DhgtRk6E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}