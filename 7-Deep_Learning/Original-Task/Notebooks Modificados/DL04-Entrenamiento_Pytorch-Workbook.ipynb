{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"DL04-Entrenamiento_Pytorch-Workbook.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Vw_LGfw4ZDtm"},"source":["# Deep Learining\n","# DL04 Entrenamiento Pytorch\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NZo0P8n_9OZB"},"source":["## <font color='blue'>Entrenando las redes neuronales</font>\n","\n","#### No ejecute el notebook completo. También tenga cuidado con el numero de epochs. El proceso puede ser lento. "]},{"cell_type":"markdown","metadata":{"id":"_Wt7PuKJUq_e"},"source":["### Función Loss o de perdida. \n","\n","La red que construimos en la parte 2, no sabe nada sobre nuestros dígitos escritos a mano. Sin embargo para que Las redes neuronales con activaciones no lineales funcionan como aproximadores de funciones universales, se debe enseñar la forma de la función. Que ocurre con las imagenes?, como le asignamos una función de aproximación o de aprendizje?. Las imágenes de dígitos escritos a mano la podemos asociar a probabilidades de clase. El poder de las redes neuronales es que podemos entrenarlas para aproximar esta función, y básicamente cualquier función con suficientes datos y tiempo de cálculo.\n","\n","![Log](https://drive.google.com/uc?export=view&id=1d7hNBU9q8x7D8XQPqDg1xqXuxrC9hyjS) \n","\n","\n","Al principio, la red es ingenua, no conoce la función que asigna las entradas a las salidas. Entrenamos la red mostrándole ejemplos de datos reales, luego ajustamos los parámetros de la red de modo que se aproxime a esta función.\n","\n","Para encontrar estos parámetros, necesitamos saber qué tan mal está prediciendo la red los resultados reales. Para esto calculamos una **función de pérdida (loss function)** (también llamada costo), una medida de nuestro error de predicción. Por ejemplo, la pérdida cuadrática media a menudo se usa en problemas de regresión y clasificación binaria.\n","$$\n","\\large \\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n","$$\n","\n","Donde $n$ es el numero de ejemplo de entrenamiento, $y_i$ son los valores reales o etiquetas, y $\\hat{y}_i$ son los valores predecidos. "]},{"cell_type":"markdown","metadata":{"id":"UXuY-j6RU6rO"},"source":["### Optimización de los pesos \n","\n","\n","\n","\n","Al minimizar esta pérdida con respecto a los parámetros de la red, podemos encontrar configuraciones donde la pérdida es mínima y la red puede predecir las etiquetas correctas con alta precisión. Encontramos este mínimo usando un proceso llamado **descenso de gradiente**. El gradiente es la pendiente de la función de pérdida y apunta en la dirección del cambio más rápido. Para llegar al mínimo en la menor cantidad de tiempo, entonces queremos seguir el gradiente (hacia abajo). Puedes pensar en esto como descender una montaña siguiendo la pendiente más empinada hasta la base.\n","\n","\n","![Log](https://drive.google.com/uc?export=view&id=1-kPnRcfH8bhPH1vzQsWrRGC_0Nptc7jR) \n"]},{"cell_type":"markdown","metadata":{"id":"52Nz_60MZDtu"},"source":["### Backpropagation\n","\n","Para redes de una sola capa, el descenso de gradiente es fácil de implementar. Sin embargo, es más complicado para redes neuronales multicapa más profundas como la que hemos construido. Lo suficientemente complicado como para que pasaron unos 30 años antes de que los investigadores descubrieran cómo entrenar redes multicapa.\n","\n","El entrenamiento de redes multicapa se realiza a través de **backpropagation**, que en realidad es solo una aplicación de la regla de la cadena del cálculo. Es más fácil de entender si convertimos una red de dos capas en una representación gráfica.\n","\n","\n","![Log](https://drive.google.com/uc?export=view&id=1I7-fkRYztOZDU1P1JTo17DCFMc6O8tIO) \n","\n","\n","En el paso directo a través de la red, nuestros datos y operaciones van de abajo hacia arriba aquí. Pasamos la entrada $x$ a través de una transformación lineal $L_1$ con pesos  $W_1$ y sesgos $b_1$. La salida luego pasa por la operación sigmoidea $S$ y otra transformación lineal $L_2$. Finalmente calculamos la pérdida $ \\ell $. Usamos la pérdida como una medida de cuán malas son las predicciones de la red. El objetivo entonces es ajustar los pesos y sesgos para minimizar la pérdida.\n","\n","Para entrenar los pesos con descenso de gradiente, propagamos el gradiente de la pérdida hacia atrás a través de la red. Cada operación tiene algún gradiente entre las entradas y salidas. A medida que enviamos los gradientes hacia atrás, multiplicamos el gradiente entrante con el gradiente para la operación. Matemáticamente, esto es solo calcular el gradiente de la pérdida con respecto a los pesos usando la regla de la cadena.\n","\n","\n","$$\n","\\large \\frac{\\partial \\ell}{\\partial W_1} = \\frac{\\partial L_1}{\\partial W_1} \\frac{\\partial S}{\\partial L_1} \\frac{\\partial L_2}{\\partial S} \\frac{\\partial \\ell}{\\partial L_2}\n","$$\n","\n","\n","Actualizamos nuestros pesos usando este gradiente con cierta tasa de aprendizaje $ \\ alpha $.\n","\n","$$\n","\\large W^\\prime_1 = W_1 - \\alpha \\frac{\\partial \\ell}{\\partial W_1}\n","$$\n","\n","La tasa de aprendizaje $ \\ alpha $ se establece de manera que los pasos de actualización de peso sean lo suficientemente pequeños como para que el método iterativo se establezca en un mínimo."]},{"cell_type":"markdown","metadata":{"id":"1a7VJFyFZDtv"},"source":["### Losses in PyTorch\n","\n","Comencemos por ver cómo calculamos el loss con PyTorch. A través del módulo `nn`, PyTorch proporciona diferentes tipos de loss como por ejemplo ` nn.CrossEntropyLoss`.  En un problema de clasificación como MNIST, estamos utilizando la función softmax para predecir las probabilidades de clase. Con una salida softmax, desea utilizar la entropía cruzada como loss. Para calcular realmente el loss, primero define el criterio y luego pasa la salida de su red y las etiquetas correctas.\n","\n","\n","Para mas información mirar [the documentation for `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss),\n","\n","> Este criterio combina `nn.LogSoftmax()` y `nn.NLLLoss()` en una sola clase. \n",">\n"]},{"cell_type":"code","metadata":{"id":"h_LcMDmVZDtw","executionInfo":{"status":"ok","timestamp":1650502563226,"user_tz":240,"elapsed":244,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}}},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","\n","# Normalizamos y transformamos. \n","\n","\n","transform = transforms.Compose([transforms.ToTensor(),\n","                              transforms.Normalize((0.5,), (0.5,)),\n","                              ])\n","# Bajamos y cargamos los datos. \n","trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"],"execution_count":130,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UW_r-Y6fVeKt"},"source":["### Un primer ejemplo utlizando CrossEntropyLoss como loss "]},{"cell_type":"code","metadata":{"id":"qfpEdZ8jZDtw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650502262192,"user_tz":240,"elapsed":38,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"a19d9e57-e075-451b-d0a1-4e981cc2c7f1"},"source":["# Contruimos una red  feed-forward.\n","model = nn.Sequential(nn.Linear(784, 128),\n","                      nn.ReLU(),\n","                      nn.Linear(128, 64),\n","                      nn.ReLU(),\n","                      nn.Linear(64, 10))\n","\n","# Definiendo el loss. Recordar que esta integrado con el softmax en el caso del CrossEntropyLoss. \n","criterion = nn.CrossEntropyLoss()\n","\n","# Obtengamos la data. \n","images, labels = next(iter(trainloader))\n","# Convirtiendo a vector.\n","images = images.view(images.shape[0], -1)\n","\n","# Forward pass, obteniendo el logits. \n","logits = model(images)\n","# Calculando el loss\n","loss = criterion(logits, labels)\n","\n","print(loss)"],"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.2975, grad_fn=<NllLossBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"Zjmm1gTzVlIH"},"source":["### Un segundoejemplo utlizando NLLLoss como loss \n","\n","https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html"]},{"cell_type":"code","metadata":{"id":"FKINvZdEZDty","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650502262192,"user_tz":240,"elapsed":36,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"050ac521-5ce4-467d-e4da-258ca618c1d0"},"source":["# Contruimos una red  feed-forward.\n","model = nn.Sequential(nn.Linear(784, 128),\n","                      nn.ReLU(),\n","                      nn.Linear(128, 64),\n","                      nn.ReLU(),\n","                      nn.Linear(64, 10),\n","                      nn.LogSoftmax(dim=1))\n","\n","\n","\n","# Definiendo el loss. \n","criterion = nn.NLLLoss()\n","\n","# Obtengamos la data. \n","images, labels = next(iter(trainloader))\n","# Convirtiendo a vector.\n","images = images.view(images.shape[0], -1)\n","\n","# Forward pass, obteniendo las probabilidades. \n","logps = model(images)\n","# Calculando el loss\n","loss = criterion(logps, labels)\n","\n","print(loss)"],"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.3149, grad_fn=<NllLossBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"RjfVZ75GZDty"},"source":["### Autograd\n","\n","\n","Ahora que sabemos cómo calcular un loss, ¿cómo lo usamos para realizar la propagación hacia atrás? Torch proporciona un módulo, 'autograd', para calcular automáticamente los gradientes de los tensores. Podemos usarlo para calcular los gradientes de todos nuestros parámetros con respecto a la pérdida. Autograd funciona haciendo un seguimiento de las operaciones realizadas en los tensores, luego retrocediendo a través de esas operaciones, calculando los gradientes en el camino. Para asegurarse de que PyTorch realiza un seguimiento de las operaciones en un tensor y calcula los gradientes, debe establecer `require_grad = True` en un tensor. Puede hacer esto en la creación con la palabra clave `require_grad`, o en cualquier momento con` x.requires_grad_ (True) `.\n","\n","Puede desactivar gradientes para un bloque de código con el `torch.no_grad()`:\n","```python\n","x = torch.zeros(1, requires_grad=True)\n",">>> with torch.no_grad():\n","...     y = x * 2\n",">>> y.requires_grad\n","False\n","```\n","Tambien podemos apagar el calculo de gradientes con `torch.set_grad_enabled(True|False)`.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4MY9_O_hW3iU"},"source":["Los gradientes son caculados respecto de alguna variable `z` con `z.backward()`."]},{"cell_type":"markdown","metadata":{"id":"GDnb3C61W61g"},"source":["#### Un ejemplo concreto con calculos de gradientes."]},{"cell_type":"code","metadata":{"id":"uuECWBvjZDtz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650502262194,"user_tz":240,"elapsed":33,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"1d0ef613-7c00-4438-a9d7-ed3ead068efc"},"source":["x = torch.randn(2,2, requires_grad=True)\n","print(x)"],"execution_count":115,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1.7898, -1.1909],\n","        [ 1.7084,  1.1207]], requires_grad=True)\n"]}]},{"cell_type":"code","metadata":{"id":"EZMba81FZDtz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650502262195,"user_tz":240,"elapsed":31,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"3b23aafb-0a82-4ad7-c48d-120309328c58"},"source":["y = x**2\n","print(y)"],"execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[3.2033, 1.4182],\n","        [2.9185, 1.2561]], grad_fn=<PowBackward0>)\n"]}]},{"cell_type":"code","source":["m = x + y\n","m"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CLERxDOigd-q","executionInfo":{"status":"ok","timestamp":1650502262195,"user_tz":240,"elapsed":27,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"1ee69fd0-8b0b-456c-a9bc-cb7ee72a20f0"},"execution_count":117,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[4.9930, 0.2273],\n","        [4.6269, 2.3768]], grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":117}]},{"cell_type":"markdown","metadata":{"id":"gQZU71QkZDt0"},"source":["A continuación podemos ver la operación que creó `y`, una operación de potencia`PowBackward0`."]},{"cell_type":"code","metadata":{"id":"5Gh9a1MzZDt0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650502262195,"user_tz":240,"elapsed":24,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"6fe481c5-082a-4374-8bb2-d6a3dfffaa67"},"source":["## grad_fn muestra la funcion generada por esta variable. \n","print(y.grad_fn)"],"execution_count":118,"outputs":[{"output_type":"stream","name":"stdout","text":["<PowBackward0 object at 0x7face9209090>\n"]}]},{"cell_type":"markdown","metadata":{"id":"U6X5EUofZDt0"},"source":["El módulo de autograd realiza un seguimiento de estas operaciones y sabe cómo calcular el gradiente de cada una. De esta manera, puede calcular los gradientes para una cadena de operaciones, con respecto a cualquier tensor. Reduzcamos el tensor `y` a un valor escalar, la media."]},{"cell_type":"code","metadata":{"id":"TU52UEFiZDt0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650502262196,"user_tz":240,"elapsed":22,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"7ce6b071-f760-445f-9576-9529c822b3b7"},"source":["z = y.mean()\n","print(z)"],"execution_count":119,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.1990, grad_fn=<MeanBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"joPJE4q0ZDt1"},"source":["Puede verificar los gradientes para `x` e` y` pero actualmente están vacíos."]},{"cell_type":"code","metadata":{"id":"JXgZGgFGZDt1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650502262197,"user_tz":240,"elapsed":20,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"33d005cb-1e8f-4c11-898a-77c5ec77bfde"},"source":["print(x.grad)"],"execution_count":120,"outputs":[{"output_type":"stream","name":"stdout","text":["None\n"]}]},{"cell_type":"markdown","metadata":{"id":"wilFOvRCZDt1"},"source":["Para calcular los gradientes, debe ejecutar el método `.backward` en una Variable,` z` por ejemplo. Esto calculará el gradiente para `z` con respecto a` x`\n","\n","$$\n","\\frac{\\partial z}{\\partial x_j} = \\frac{\\partial}{\\partial x_j}\\left[\\frac{1}{4}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n","$$"]},{"cell_type":"code","metadata":{"id":"JCxXKPMIZDt2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650502262470,"user_tz":240,"elapsed":290,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"5cbfb78b-07fb-436a-e314-6df7b4d849d9"},"source":["z.backward()\n","print(x)\n","print(x.grad)\n","print(x/2)"],"execution_count":121,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1.7898, -1.1909],\n","        [ 1.7084,  1.1207]], requires_grad=True)\n","tensor([[ 0.8949, -0.5954],\n","        [ 0.8542,  0.5604]])\n","tensor([[ 0.8949, -0.5954],\n","        [ 0.8542,  0.5604]], grad_fn=<DivBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"4iHbvJgvZDt2"},"source":["### Loss and Autograd juntos\n","\n","\n","Cuando creamos una red con PyTorch, todos los parámetros se inicializan con `require_grad = True`. Esto significa que cuando calculamos el loss y llamamos `loss.backward ()`, se calculan los gradientes para los parámetros. Estos gradientes se utilizan para actualizar los pesos con descenso de gradiente. "]},{"cell_type":"code","metadata":{"id":"8PUFjD0nZDt2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650502262470,"user_tz":240,"elapsed":27,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"2c46985a-b6be-4f93-8ea0-7d56e4f150d0"},"source":["# Construimos una red  feed-forward.\n","model = nn.Sequential(nn.Linear(784, 128),\n","                      nn.ReLU(),\n","                      nn.Linear(128, 64),\n","                      nn.ReLU(),\n","                      nn.Dropout(0.2),\n","                      nn.Linear(64, 10),\n","                      nn.Dropout(0.2),\n","                      nn.LogSoftmax(dim=1))\n","\n","criterion = nn.NLLLoss()\n","images, labels = next(iter(trainloader))\n","images = images.view(images.shape[0], -1)\n","\n","logps = model(images)\n","loss = criterion(logps, labels)\n","loss"],"execution_count":122,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.3529, grad_fn=<NllLossBackward0>)"]},"metadata":{},"execution_count":122}]},{"cell_type":"code","metadata":{"id":"TzjusbaXZDt2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650502262471,"user_tz":240,"elapsed":25,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"33da054f-9373-4124-ac42-2a11a59f9d85"},"source":["print('Before backward pass: \\n', model[0].weight.grad)\n","\n","loss.backward()\n","\n","print('After backward pass: \\n', model[0].weight.grad)"],"execution_count":123,"outputs":[{"output_type":"stream","name":"stdout","text":["Before backward pass: \n"," None\n","After backward pass: \n"," tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [-0.0066, -0.0066, -0.0066,  ..., -0.0066, -0.0066, -0.0066],\n","        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n","        ...,\n","        [ 0.0004,  0.0004,  0.0004,  ...,  0.0004,  0.0004,  0.0004],\n","        [-0.0021, -0.0021, -0.0021,  ..., -0.0021, -0.0021, -0.0021],\n","        [-0.0077, -0.0077, -0.0077,  ..., -0.0077, -0.0077, -0.0077]])\n"]}]},{"cell_type":"code","source":["print('After backward pass: \\n', model[2].weight.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nKZq5fjpieC8","executionInfo":{"status":"ok","timestamp":1650502262472,"user_tz":240,"elapsed":20,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"c5842c4a-d809-48e9-f0ba-04b71750d133"},"execution_count":124,"outputs":[{"output_type":"stream","name":"stdout","text":["After backward pass: \n"," tensor([[ 0.0000e+00,  1.5457e-02,  0.0000e+00,  ...,  1.9630e-04,\n","          1.3863e-02,  1.3885e-02],\n","        [ 0.0000e+00,  1.2356e-02, -2.1035e-04,  ..., -1.6258e-04,\n","          1.6037e-02,  5.3451e-03],\n","        [ 0.0000e+00,  1.3286e-02,  9.1137e-04,  ..., -4.3884e-04,\n","          4.7505e-03,  1.3703e-02],\n","        ...,\n","        [ 0.0000e+00, -9.6436e-04,  0.0000e+00,  ..., -5.7731e-06,\n","         -3.4982e-03, -2.3052e-03],\n","        [ 0.0000e+00,  5.9452e-03,  0.0000e+00,  ..., -2.6426e-04,\n","          2.3122e-04,  9.3862e-03],\n","        [ 0.0000e+00, -2.0261e-02,  0.0000e+00,  ...,  9.6721e-05,\n","         -1.8659e-02, -1.8930e-02]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"ECQjpT4vZDt2"},"source":["### Entrenemos la red. \n","\n","Hay una última pieza que necesitamos para comenzar a entrenar, un optimizador que usaremos para actualizar los pesos con los gradientes. Los obtenemos del paquete [`optim` package](https://pytorch.org/docs/stable/optim.html). Por ejemplo, podemos usar el descenso de gradiente estocástico con `optim.SGD`. Se puede ver cómo definir un optimizador a continuación."]},{"cell_type":"code","source":["next(model.parameters())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-JwZ-3QTlgfP","executionInfo":{"status":"ok","timestamp":1650502262472,"user_tz":240,"elapsed":16,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"d56eb8e1-bf15-48f9-dba6-fd94d624f489"},"execution_count":125,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-0.0141,  0.0150, -0.0017,  ..., -0.0330,  0.0102,  0.0274],\n","        [ 0.0197, -0.0100, -0.0196,  ..., -0.0207, -0.0165,  0.0068],\n","        [-0.0163, -0.0140, -0.0137,  ..., -0.0130,  0.0003,  0.0286],\n","        ...,\n","        [ 0.0015,  0.0125,  0.0178,  ...,  0.0104, -0.0154, -0.0170],\n","        [ 0.0272,  0.0074,  0.0161,  ...,  0.0293,  0.0246,  0.0272],\n","        [ 0.0140, -0.0206, -0.0322,  ..., -0.0152, -0.0067,  0.0216]],\n","       requires_grad=True)"]},"metadata":{},"execution_count":125}]},{"cell_type":"code","source":["print(\"Antes de la actualizacion de pesos\")\n","model[0].weight"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XV6WY1W7lkIS","executionInfo":{"status":"ok","timestamp":1650502262473,"user_tz":240,"elapsed":13,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"1e0695e3-d2ae-4d0b-dcd8-9065ce2b3220"},"execution_count":126,"outputs":[{"output_type":"stream","name":"stdout","text":["Antes de la actualizacion de pesos\n"]},{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-0.0141,  0.0150, -0.0017,  ..., -0.0330,  0.0102,  0.0274],\n","        [ 0.0197, -0.0100, -0.0196,  ..., -0.0207, -0.0165,  0.0068],\n","        [-0.0163, -0.0140, -0.0137,  ..., -0.0130,  0.0003,  0.0286],\n","        ...,\n","        [ 0.0015,  0.0125,  0.0178,  ...,  0.0104, -0.0154, -0.0170],\n","        [ 0.0272,  0.0074,  0.0161,  ...,  0.0293,  0.0246,  0.0272],\n","        [ 0.0140, -0.0206, -0.0322,  ..., -0.0152, -0.0067,  0.0216]],\n","       requires_grad=True)"]},"metadata":{},"execution_count":126}]},{"cell_type":"code","metadata":{"id":"kaRYwZYxZDt3","executionInfo":{"status":"ok","timestamp":1650502262473,"user_tz":240,"elapsed":9,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}}},"source":["from torch import optim\n","\n","# Los optimizadores requieren los parámetros para optimizar y una tasa de aprendizaje\n","optimizer = optim.SGD(model.parameters(), lr=1)"],"execution_count":127,"outputs":[]},{"cell_type":"code","source":["optimizer.step()"],"metadata":{"id":"V6v0S_Q5mDat","executionInfo":{"status":"ok","timestamp":1650502262473,"user_tz":240,"elapsed":8,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}}},"execution_count":128,"outputs":[]},{"cell_type":"code","source":["print(\"Despues de la actualizacion de pesos\")\n","model[0].weight"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vi_vehU8mPv8","executionInfo":{"status":"ok","timestamp":1650502263543,"user_tz":240,"elapsed":3,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"ec38cce2-d0e9-4daa-dbdb-3a5aee397911"},"execution_count":129,"outputs":[{"output_type":"stream","name":"stdout","text":["Despues de la actualizacion de pesos\n"]},{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-0.0141,  0.0150, -0.0017,  ..., -0.0330,  0.0102,  0.0274],\n","        [ 0.0263, -0.0034, -0.0129,  ..., -0.0141, -0.0098,  0.0134],\n","        [-0.0161, -0.0138, -0.0136,  ..., -0.0129,  0.0005,  0.0288],\n","        ...,\n","        [ 0.0011,  0.0122,  0.0174,  ...,  0.0100, -0.0158, -0.0173],\n","        [ 0.0293,  0.0095,  0.0182,  ...,  0.0314,  0.0267,  0.0293],\n","        [ 0.0217, -0.0129, -0.0245,  ..., -0.0075,  0.0010,  0.0292]],\n","       requires_grad=True)"]},"metadata":{},"execution_count":129}]},{"cell_type":"code","source":["#Definicion del iterador: \n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"],"metadata":{"id":"QckEWAQVnqPV","executionInfo":{"status":"ok","timestamp":1650502606477,"user_tz":240,"elapsed":511,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}}},"execution_count":131,"outputs":[]},{"cell_type":"code","source":["for imagenes, labels in trainloader:\n","    print(imagenes.shape,labels.shape)\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"lJTdm820nxRb","executionInfo":{"status":"error","timestamp":1650502641337,"user_tz":240,"elapsed":238,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"66f12557-9eac-4df8-df71-4a76231b9dde"},"execution_count":132,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 1, 28, 28]) torch.Size([64])\n"]},{"output_type":"error","ename":"ZeroDivisionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-132-9b0fa80f4439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimagenes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagenes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;36m0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"]}]},{"cell_type":"code","source":["#definimos el modelo \n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) #generamos un iterador utilizando pytorch\n","optimizer = optim.SGD(model.parameters(), lr=0.01) #definimos el optimizador con los parametros a actualizar\n","\n","for inputs,labels in trainloader:\n","    outputs = model(inputs) # foward pass (para generar el output de nuestra red neuronal, probabilidades)\n","    loss = criterion(outputs,labels) #computo de la funcion de perdida\n","    loss.backward() # Retropropagacion\n","    optimizer.step() # Para la actualizacion de los pesos"],"metadata":{"id":"yJuKHRAgmpOm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YW-p8u1uqIWs"},"source":["## <font color='green'>**Actividad 4**</font>\n","\n","Ahora sabemos cómo usar todas las partes individuales, así que es momento de ver cómo funcionan juntas.  El proceso general con PyTorch:\n","\n","\n","* Hacer un forward a través de la red\n","* Use la salida de red para calcular el loss\n","* Realice un paso hacia atrás a través de la red con `loss.backward ()` para calcular los gradientes\n","* Da un paso con el optimizador para actualizar los pesos\n","\n","### Entrenamiento.\n","\n","Ahora pondremos este algoritmo en un ciclo para que podamos ver todas las imágenes. Alguna nomenclatura, una pasada a través de todo el conjunto de datos se llama **epoch**. Así que aquí vamos a recorrer el \"trainloader\" para obtener nuestros lotes de entrenamiento. Para cada lote, haremos un pase de entrenamiento donde calcularemos la pérdida, haremos un pase hacia atrás y actualizaremos los pesos."]},{"cell_type":"markdown","metadata":{"id":"fPUEL24xpleS"},"source":["### Tenga cuidado con el numero de epochs. El proceso puede ser lento. \n","\n","**Ayuda**\n","\n","1. Defina una red por ejemplo:\n","\n","\n","\n","```\n","model = nn.Sequential(nn.Linear(784, 128),\n","                      nn.ReLU(),\n","                      nn.Linear(128, 64),\n","                      nn.ReLU(),\n","                      nn.Linear(64, 10),\n","                      nn.LogSoftmax(dim=1))\n","```\n","2. Defina el loss\n","\n","\n","\n","```\n","criterion = nn.NLLLoss()\n","```\n","\n","\n","3. Defina el optimizador\n","\n","\n","\n","```\n","optimizer = optim.SGD(model.parameters(), lr=0.003)\n","```\n","\n","\n","4. Itere respecto de las epochs:\n","\n","\n","\n","```\n","for e in range(epochs):\n","    running_loss = 0\n","    for images, labels in trainloader:\n","    # Genere un vector de 784 caracteristicas. \n","    images = images.view(images.shape[0], -1)\n","    #Realice el forward\n","    # Calcule el loss.\n","    # Realice el backward()\n","    # Optimice\n","    # Acumule el loss.\n","```\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"FsZNqsGyZDt3","executionInfo":{"status":"ok","timestamp":1650503648150,"user_tz":240,"elapsed":219,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}}},"source":["# Entrene aquí su red.\n","model = nn.Sequential(nn.Linear(784, 256),\n","                      nn.ReLU(),\n","                      nn.Linear(256, 128),\n","                      nn.ReLU(),\n","                      nn.Linear(128, 64),\n","                      nn.ReLU(),\n","                      nn.Linear(64, 10),\n","                      nn.LogSoftmax(dim=1))\n","\n","criterion = nn.NLLLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.003)\n"],"execution_count":133,"outputs":[]},{"cell_type":"code","source":["epochs = 10\n","for e in range(epochs):\n","    print(f\"epoch {e + 1}\")\n","    running_loss = 0\n","    \n","    for images, labels in trainloader:\n","        optimizer.zero_grad()\n","        # Genere un vector de 784 caracteristicas. \n","        images = images.view(images.shape[0], -1)\n","        output = model(images)\n","        loss = criterion(output, labels)\n","        running_loss += loss\n","        loss.backward()\n","        optimizer.step()\n","        #Realice el forward\n","        # Calcule el loss.\n","        # Realice el backward()\n","        # Optimice\n","        # Acumule el loss.\n","    print(f\"loss promedio de la epoch {e + 1}: {running_loss/len(trainloader)}\")\n","    print(\"========================\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GReqcEmE53Ep","executionInfo":{"status":"ok","timestamp":1650503940766,"user_tz":240,"elapsed":136543,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"cf80c49b-ead8-4aec-b66e-b8324266f5e0"},"execution_count":134,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 1\n","loss promedio de la epoch 1: 2.2536044120788574\n","========================\n","epoch 2\n","loss promedio de la epoch 2: 1.7899373769760132\n","========================\n","epoch 3\n","loss promedio de la epoch 3: 0.8942901492118835\n","========================\n","epoch 4\n","loss promedio de la epoch 4: 0.5634230375289917\n","========================\n","epoch 5\n","loss promedio de la epoch 5: 0.465884804725647\n","========================\n","epoch 6\n","loss promedio de la epoch 6: 0.4182609021663666\n","========================\n","epoch 7\n","loss promedio de la epoch 7: 0.38633662462234497\n","========================\n","epoch 8\n","loss promedio de la epoch 8: 0.36207613348960876\n","========================\n","epoch 9\n","loss promedio de la epoch 9: 0.3424886465072632\n","========================\n","epoch 10\n","loss promedio de la epoch 10: 0.3260578513145447\n","========================\n"]}]},{"cell_type":"markdown","metadata":{"id":"7YcxpL6PZDt3"},"source":["Con la red entrenada, podemos verificar sus predicciones. Utilice las siguientes funciones. \n"]},{"cell_type":"code","metadata":{"id":"HF9WiE7AqlzB","executionInfo":{"status":"ok","timestamp":1650503940768,"user_tz":240,"elapsed":14,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def view_classify(img, ps, version=\"MNIST\"):\n","    ''' Function for viewing an image and it's predicted classes.\n","    '''\n","    ps = ps.data.numpy().squeeze()\n","\n","    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n","    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n","    ax1.axis('off')\n","    ax2.barh(np.arange(10), ps)\n","    ax2.set_aspect(0.1)\n","    ax2.set_yticks(np.arange(10))\n","    if version == \"MNIST\":\n","        ax2.set_yticklabels(np.arange(10))\n","    elif version == \"Fashion\":\n","        ax2.set_yticklabels(['T-shirt/top',\n","                            'Trouser',\n","                            'Pullover',\n","                            'Dress',\n","                            'Coat',\n","                            'Sandal',\n","                            'Shirt',\n","                            'Sneaker',\n","                            'Bag',\n","                            'Ankle Boot'], size='small');\n","    ax2.set_title('Class Probability')\n","    ax2.set_xlim(0, 1.1)\n","\n","    plt.tight_layout()\n","\n"," "],"execution_count":135,"outputs":[]},{"cell_type":"code","metadata":{"id":"-W2K84HqZDt3","colab":{"base_uri":"https://localhost:8080/","height":253},"executionInfo":{"status":"ok","timestamp":1650503941100,"user_tz":240,"elapsed":343,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"bbf3d894-9fdb-4503-e8d9-99fce0380203"},"source":["%matplotlib inline\n","\n","images, labels = next(iter(trainloader))\n","\n","img = images[0].view(1, 784)\n","# Aqui sirve apagar los gradientes para ser mas eficientes. \n","with torch.no_grad():\n","    logps = model(img) # Este es el modelo\n","\n","# La salida de la red son logaritmos de probabilidades (Por la función de perdida utilizada), \n","# tenemos que aplicar una exponencial para obtener probabilidades. \n","ps = torch.exp(logps)\n","view_classify(img.view(1, 28, 28), ps)\n","\n","#Modificacion\n","#Si necesitan el output que puede generar en "],"execution_count":136,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x648 with 2 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAagAAADsCAYAAAAhDDIOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUcElEQVR4nO3dfZBldX3n8ffHAWJGHrSY0ZIHGRR0IVAqO4uwhkkMPgCxIG6yAQyyGEvEoKv4tCRrVpNspaImkt0KCRAlSqKIGEmIisIGdNBiiDNA5ElSw8Mgg8rgw/AwURn47h/3YF3bvnd62nP7nNu8X1Vdc/v8zr330z0wn/6d8+tzUlVIktQ3T+o6gCRJs7GgJEm9ZEFJknrJgpIk9ZIFJUnqJQtKktRLFpSkiUny3iR/13WO7ZVkRZJKssM8n19J9hsx9ltJLp9t3yTnJPn9+aVefCwoST+TJK9OsjbJQ0m+meSyJL/YUZZK8nCTZWOSDyZZ0kWWUarqY1X18hFjp1XVHwEk+eUk9yxsun6xoCTNW5K3AX8O/DHwDOBZwF8Cx3UY6/lVtTNwJPBq4PUzd5jvzEgLy4KSNC9JdgP+EDi9qj5dVQ9X1SNV9U9V9c4Rz7k4ybeSbE6yOskvDI0dk+SWJA82s593NNuXJflMku8n+W6Sq5Ns89+uqvo6cDVw0NAhu9cluRu4MsmTkrw7yYYk9yW5oPmahv12knubmeE7hrIemuSaJtM3k/xFkp1mPPeYJHckuT/JBx7PnOSUJF8e8f35SJL/neQpwGXAHs1s8KEkeyTZkmT3of0PSbIpyY7b+n5MIwtK0nwdDjwZuGQ7nnMZsD/wdOA64GNDYx8G3lBVuwAHAVc2298O3AMsZzBL+z1gm9doS3IgcARw/dDmXwIOAF4BnNJ8vAR4NrAz8BczXuYlTd6XA/8jyUub7Y8CZwDLGHwfjgR+Z8ZzXwWsBA5hMKP87W1lflxVPQwcDdxbVTs3H/cCXwR+c2jX1wCfqKpH5vra08SCkjRfuwP3V9XWuT6hqs6vqger6ofAe4HnD81aHgEOTLJrVX2vqq4b2v5MYJ9mhnZ1jb+I6HVJvgf8E/Ah4G+Gxt7bzPT+Hfgt4INVdUdVPQT8LnDCjMN/f9Dsf2PzOic2X8e6qlpTVVur6i7gXAblN+x9VfXdqrqbwWHQE+f6fRrjo8BJAM25tROBv23hdXvJgpI0X98Bls31fE6SJUn+JMntSR4A7mqGljV//jpwDLAhyZeSHN5s/wCwHri8OWR25jbe6pCqelpVPaeq3l1Vjw2NfWPo8R7AhqHPNwA7MJilzbb/huY5JHluc9jxW83X8sdDX8fY5/6M/pFBie8LvAzYXFX/0sLr9pIFJWm+rgF+CPzaHPd/NYNDXS8FdgNWNNsDUFVfrarjGBz++wfgk832B6vq7VX1bOBY4G1Jjpxn5uGZ173APkOfPwvYCnx7aNveM8bvbR7/FfB1YP+q2pXBYcfMeK9Rz51P1sGGqh8w+L6cxODw3qKdPYEFJWmeqmoz8L+As5P8WpKlSXZMcnSS98/ylF0YFNp3gKUMZh0AJNmp+f2g3ZrzKQ8AjzVjr0yyX5IAmxmc/3nsp159+10InJFk3yQ7N3kumnHI8vebr+sXgNcCFw19LQ8ADyX5D8AbZ3n9dyZ5WpK9gbcMPXeuvg3sPsvCjQsYnDs7FgtKkmZXVX8GvA14N7CJwWGtNzGYAc10AYNDXRuBW4A1M8ZfA9zVHDI7jcE5IhgsUvh/wEMMZm1/WVVXtRD/fAb/wK8G7gR+ALx5xj5fYnB48Z+BP62qx3/B9h0MZoQPAn/N7OXzj8A64AbgswwWgcxZswrxQuCOZrXgHs32rzAo6OuqasO415h28YaFkjRdklwJfLyqPtR1lkmyoCRpiiT5T8AVwN5V9WDXeSbJQ3ySNCWSfJTB4c63LvZyAmdQkqSeGvv7Cy970n+1vfSEd8VjF89cPixpAXiIT5LUS17RV+rQsmXLasWKFV3HkDq1bt26+6tq+cztFpTUoRUrVrB27dquY0idSjLr73N5iE+S1EsWlCSplywoSVIvWVCSpF6yoCRJvWRBSZJ6yYKSJPWSBSVJ6iULSpLUSxaUJKmXLCipZUnekuSmJDcneWvXeaRpZUFJLUpyEPB64FDg+cArk+zXbSppOllQUrsOAK6tqi1VtRX4EvBfOs4kTSULSmrXTcARSXZPshQ4Bth7eIckpyZZm2Ttpk2bOgkpTQMLSmpRVd0KvA+4HPg8cAPw6Ix9zquqlVW1cvnyn7oFjqSGBSW1rKo+XFX/sapWAd8D/q3rTNI08oaFi9T6sw4bOXb78ee0/n4nb1g16/ZvH/5A6+/Vd0meXlX3JXkWg/NPo/8yJI1kQUnt+/skuwOPAKdX1fe7DiRNIwtKallVHdF1Bmkx8ByUJKmXLChJUi9ZUJKkXrKgJEm95CKJKfaMa3YdOfaFfRZuKTnABfusnv0514x+zhNxCbqkuXMGJXXoxo2bu44g9ZYFJUnqJQtKktRLFpTUsiRnNDcrvCnJhUme3HUmaRpZUFKLkuwJ/HdgZVUdBCwBTug2lTSdLCipfTsAP59kB2ApcG/HeaSp5DLzHtjyqheNHLv67HPn9ZrjloTPd3n3+rMOHD04Ypn5qOXnAK/gBfPK0WdVtTHJnwJ3A/8OXF5Vl3ccS5pKzqCkFiV5GnAcsC+wB/CUJCfN2OfHd9R9dIvLzKVRLCipXS8F7qyqTVX1CPBp4D8P7zB8R90lS3frJKQ0DSwoqV13A4clWZokwJHArR1nkqaSBSW1qKquBT4FXAfcyOD/sfM6DSVNKRdJSC2rqvcA7+k6hzTtnEFJknrJGVQP7Puu+Z2iOOL0N4wcW3rJtfON06pxy93Bq5lLGs0ZlNShg/d0FZ80igUlSeolC0qS1EsWlCSplywoSVIvuYpvgaw/67CRY8/glpFj07BSb5wn2sViJbXHGZQkqZcsKKlFSZ6X5IahjweSvLXrXNI08hCf1KKqug0Gxy6TLAE2Apd0GkqaUs6gpMk5Eri9qjZ0HUSaRhaUNDknABfO3Dh8w8JNmzZ1EEuaDhaUNAFJdgKOBS6eOTZ8w8Lly5cvfDhpSngOaoHsd8aakWPfHvO8pfR/Kfk4z7notJFj+zH6e7IIHA1cV1Xj/noljeEMSpqME5nl8J6kubOgpJYleQrwMuDTXWeRppmH+KSWVdXDwO5d55CmnTMoSVIvWVCSpF6yoCRJveQ5KM3Z7cefs93PGbe8XpLGcQYlSeolC0rq0I0bN3cdQeotC0qS1EsWlCSplywoqWVJnprkU0m+nuTWJId3nUmaRq7ik9r3f4DPV9VvNFc1X9p1IGkaWVD6CVte9aIxozeMHBl11fJFfsXyn5JkN2AVcApAVf0I+FGXmaRp5SE+qV37ApuAv0lyfZIPNRePlbSdLCipXTsAhwB/VVUvBB4GzhzeYfiOuo9ucZm5NIoFJbXrHuCeqnr8TpOfYlBYPzZ8R90lS3db8IDStLCgpBZV1beAbyR5XrPpSOCWDiNJU8tFElL73gx8rFnBdwfw2o7zSFPJgpJaVlU3ACu7ziFNOwtKP+Hqs8+d1/P2WF0tJ5H0ROc5KElSL1lQUocO3tNVfNIoFpQkqZcsKElSL1lQkqResqAkSb3kMvMnoPVnHTZmdPQVy0/esGrk2NJLrh05Jknz4QxKktRLzqCkliW5C3gQeBTYWlVeVUKaBwtKmoyXVNX9XYeQppmH+CRJvWRBSe0r4PIk65KcOnNw+IaFmzZt6iCeNB0sKKl9v1hVhwBHA6cn+Ynlj8M3LFy+fHk3CaUp4DmoRWrLq140cuz248+Z12ve+f4DRo4txWXmj6uqjc2f9yW5BDgUWN1tKmn6OIOSWpTkKUl2efwx8HLgpm5TSdPJGZTUrmcAlySBwf9fH6+qz3cbSZpOFpTUoqq6A3h+1zmkxcBDfJKkXrKgJEm9ZEFJknrJc1BTbNxS8n3fdWvr73fvqoweXDXuCumz22N1jRzz6uiSnEFJknrJgpIk9ZIFJUnqJQtKktRLFpQkqZcsKGkCkixJcn2Sz3SdRZpWLjPvgXHLxcct7Z7vVcnnaz7vd/KGVSPH7lw9+uroi8BbgFuBXbsOIk0rZ1BSy5LsBfwq8KGus0jTzIKS2vfnwLuAx2Yb9I660txYUFKLkrwSuK+q1o3axzvqSnNjQUntejFwbJK7gE8Av5Lk77qNJE0nC0pqUVX9blXtVVUrgBOAK6vqpI5jSVPJgpIk9ZLLzLfT+rNGX7V7/su+b5jn80Ybt7z7K2sOnNdrzu/q4w+Mfg6L+4rlVfVF4Isdx5CmljMoSVIvWVCSpF6yoCRJvWRBSZJ6yYKSOnTjxs1dR5B6y4KSJPXSol5mPu4q4eNcffa5Y0bbXxI+CXe+f/SVwve7ZM0CJpGk+XEGJUnqJQtKalGSJyf5lyT/muTmJH/QdSZpWi3qQ3xSB34I/EpVPZRkR+DLSS6rKo+rStvJgpJaVFUFPNR8umPzMfoaUZJG8hCf1LIkS5LcANwHXFFVi/uig9KEWFBSy6rq0ap6AbAXcGiSg4bHh++o++gWfw9KGmVRHOIbdYXxcVcXf85Fp40ce8UeL9ju94LxV/sev3R9fo44/Q0jx0ZfXVwLpaq+n+Qq4CjgpqHt5wHnAfzcM/f38J80gjMoqUVJlid5avP454GXAV/vNpU0nRbFDErqkWcCH02yhMEPgJ+sqs90nEmaShaU1KKq+hrwwq5zSIuBh/gkSb1kQUmSesmCkjp08J67dR1B6q1enYMad/Xxtq8wPm5J+DgvPuyWkWMXHL96Xq85jkvJJT1ROYOSJPVSr2ZQ0hPNjRs3s+LMz3YdQ9pud/3Jr078PZxBSZJ6yYKSJPWSBSVJ6iULSmpRkr2TXJXkluaOum/pOpM0rRZ8kcT8l5Jvv5M3rBo5du+qjBy7/eztX7b+s2S58/0HjBxzKfnU2Qq8vaquS7ILsC7JFVU1+vcTJM3KGZTUoqr6ZlVd1zx+ELgV2LPbVNJ0sqCkCUmygsGFY6+dsd0bFkpzYEFJE5BkZ+DvgbdW1QPDY1V1XlWtrKqVS5Z6qSNpFAtKalmSHRmU08eq6tNd55GmlQUltShJgA8Dt1bVB7vOI02zBV/FN271XNsu2GfMxVvHjc3Tcy46beTYfmesGTm2FFfqLSIvBl4D3Jjk8eWgv1dVn+swkzSVvBaf1KKq+jKwcD+FSYuYh/gkSb3kDErq0MF77sbaBbgqtDSNnEFJknrJgpIk9ZIFJUnqpQU/B7XH6ho9ePzC5Rh38davrDlw5Ni45eL7MXpMms2NG73UkTSKMyhJUi9ZUJKkXrKgpBYlOT/JfUlu6jqLNO0sKKldHwGO6jqEtBhYUFKLqmo18N2uc0iLgQUlSeqlBV9mvvSS0VfufsUlL1jAJA+MHHG5uCYpyanAqQBLdl3ecRqpv5xBSQvMO+pKc2NBSZJ6yYKSWpTkQuAa4HlJ7knyuq4zSdPK221ILaqqE7vOIC0WzqAkSb1kQUmSesmCkjp08J6u4pNGsaAkSb1kQUmSesmCkiT1kgUlSeolC0qS1EsWlCSplywoqWVJjkpyW5L1Sc7sOo80rSwoqUVJlgBnA0cDBwInJjmw21TSdLKgpHYdCqyvqjuq6kfAJ4DjOs4kTSULSmrXnsA3hj6/p9n2Y0lOTbI2ydpNmzYtaDhpmlhQ0gIbvmHh8uXeUVcaxYKS2rUR2Hvo872abZK2kwUlteurwP5J9k2yE3ACcGnHmaSp5A0LpRZV1dYkbwK+ACwBzq+qmzuOJU0lC0pqWVV9Dvhc1zmkaechPklSL1lQkqResqAkSb1kQUmSesmCkiT1kgUlSeolC0qS1EsWlCSplywoSVIvWVCSpF7yUkdSh9atW/dQktu6zjFkGXB/1yEaZpndYsyyz2wbLSipW7dV1cquQzwuydq+5DHL7J5IWcYW1BWPXZxJvbEkSeN4DkqS1EsWlNSt87oOMEOf8phldk+YLKmqSb6+JEnz4gxKktRLFpS0AJIcleS2JOuTnDnL+M8luagZvzbJig6zvC3JLUm+luSfk8y6BHghsgzt9+tJKslEV6/NJU+S32y+Pzcn+XhXWZI8K8lVSa5v/q6OmVCO85Pcl+SmEeNJ8n+bnF9Lckhrb15VfvjhxwQ/gCXA7cCzgZ2AfwUOnLHP7wDnNI9PAC7qMMtLgKXN4zd2maXZbxdgNbAGWNnx39P+wPXA05rPn95hlvOANzaPDwTumlCWVcAhwE0jxo8BLgMCHAZc29Z7O4OSJu9QYH1V3VFVPwI+ARw3Y5/jgI82jz8FHJlkEr/msc0sVXVVVW1pPl0D7DWBHHPK0vgj4H3ADyaUY3vyvB44u6q+B1BV93WYpYBdm8e7AfdOIkhVrQa+O2aX44ALamAN8NQkz2zjvS0oafL2BL4x9Pk9zbZZ96mqrcBmYPeOsgx7HYOfjidhm1maw0V7V9VnJ5Rhu/IAzwWem+QrSdYkOarDLO8FTkpyD/A54M0TyrIt2/vf1Jx5JQlJs0pyErAS+KWO3v9JwAeBU7p4/xF2YHCY75cZzCxXJzm4qr7fQZYTgY9U1Z8lORz42yQHVdVjHWSZCGdQ0uRtBPYe+nyvZtus+yTZgcEhm+90lIUkLwX+J3BsVf1wAjnmkmUX4CDgi0nuYnB+49IJLpSYy/fmHuDSqnqkqu4E/o1BYXWR5XXAJwGq6hrgyQyujbfQ5vTf1HxYUNLkfRXYP8m+SXZisAji0hn7XAr8t+bxbwBXVnMGeqGzJHkhcC6DcprUOZZtZqmqzVW1rKpWVNUKBufDjq2qtV3kafwDg9kTSZYxOOR3R0dZ7gaObLIcwKCgNk0gy7ZcCpzcrOY7DNhcVd9s44U9xCdNWFVtTfIm4AsMVmedX1U3J/lDYG1VXQp8mMEhmvUMTkif0GGWDwA7Axc36zTurqpjO8qyYOaY5wvAy5PcAjwKvLOqWp/pzjHL24G/TnIGgwUTp0zih5okFzIo5WXN+a73ADs2Oc9hcP7rGGA9sAV4bWvvPZkf0iRJ+tl4iE+S1EsWlCSplywoSVIvWVCSpF6yoCRJvWRBSZJ6yYKSJPWSBSVJ6qX/D3KDbZ6c9EqcAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# Seccion Adicional"],"metadata":{"id":"37RqdXFMGglO","executionInfo":{"status":"ok","timestamp":1650503941102,"user_tz":240,"elapsed":42,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}}},"execution_count":137,"outputs":[]},{"cell_type":"code","source":["images = images.view(images.shape[0], -1)\n","output = model(images)\n","output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UdBSuFxOt1Up","executionInfo":{"status":"ok","timestamp":1650504221679,"user_tz":240,"elapsed":244,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"54dab788-e54e-451b-efbd-14074a312e76"},"execution_count":147,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 10])"]},"metadata":{},"execution_count":147}]},{"cell_type":"code","source":["labels.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RFmAI1PZtCvP","executionInfo":{"status":"ok","timestamp":1650504223835,"user_tz":240,"elapsed":246,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"0d56196d-c489-4247-b4e6-3cee1862b7ba"},"execution_count":148,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64])"]},"metadata":{},"execution_count":148}]},{"cell_type":"code","source":["model[0].weight"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59WqQLli83sy","executionInfo":{"status":"ok","timestamp":1650504224204,"user_tz":240,"elapsed":3,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"7f5996c7-cc07-463b-f07d-6e9a64422be5"},"execution_count":149,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[ 0.0020, -0.0079, -0.0199,  ...,  0.0178,  0.0171, -0.0172],\n","        [ 0.0263,  0.0357,  0.0094,  ..., -0.0015,  0.0087,  0.0327],\n","        [-0.0089, -0.0332,  0.0257,  ...,  0.0126, -0.0143, -0.0337],\n","        ...,\n","        [ 0.0295,  0.0326,  0.0197,  ...,  0.0089, -0.0206, -0.0113],\n","        [ 0.0045,  0.0269, -0.0349,  ...,  0.0188, -0.0121, -0.0168],\n","        [ 0.0074,  0.0270,  0.0248,  ..., -0.0345, -0.0158, -0.0164]],\n","       requires_grad=True)"]},"metadata":{},"execution_count":149}]},{"cell_type":"code","source":["output_probs = nn.Softmax(dim=1)(output)\n","output_probs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-wxm-ipxFJL6","executionInfo":{"status":"ok","timestamp":1650504225762,"user_tz":240,"elapsed":239,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"b2d8efaf-6edb-4da8-b0ab-8f13232c1970"},"execution_count":150,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 10])"]},"metadata":{},"execution_count":150}]},{"cell_type":"code","source":["output_probs_array = output_probs.detach().numpy() #transformamos de un tensor a una matriz de numpy\n","output_array = output_probs_array.argmax(axis=1)\n","output_array"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LfSUy_JEFl6Y","executionInfo":{"status":"ok","timestamp":1650504227538,"user_tz":240,"elapsed":330,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"33ccea13-dc0e-4591-f133-fe31c31819a1"},"execution_count":151,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 9, 5, 2, 2, 4, 9, 5, 3, 4, 8, 7, 6, 2, 1, 0, 0, 6, 4, 7, 6, 9,\n","       4, 4, 5, 2, 7, 5, 1, 9, 8, 7, 7, 1, 5, 8, 7, 4, 3, 0, 4, 5, 3, 5,\n","       8, 0, 2, 1, 6, 2, 6, 7, 6, 6, 0, 3, 8, 6, 6, 5, 0, 6, 2, 5])"]},"metadata":{},"execution_count":151}]},{"cell_type":"code","source":["y_true = labels.numpy() #transformamos las etiquetas de dicho batch a un vector de numpy\n","y_true"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yi3fmlDYF6_R","executionInfo":{"status":"ok","timestamp":1650504228449,"user_tz":240,"elapsed":5,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"0fe3502c-3d98-4680-d2f0-e4b486d8779e"},"execution_count":152,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 9, 5, 2, 2, 4, 9, 5, 3, 4, 8, 7, 6, 7, 7, 0, 0, 4, 4, 7, 6, 9,\n","       4, 4, 5, 2, 7, 5, 3, 9, 8, 7, 7, 1, 5, 8, 7, 4, 3, 0, 4, 5, 5, 5,\n","       8, 0, 2, 1, 6, 6, 6, 7, 6, 6, 0, 3, 8, 6, 6, 5, 0, 6, 2, 5])"]},"metadata":{},"execution_count":152}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(y_true,output_array))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JPB-v0M0GCau","executionInfo":{"status":"ok","timestamp":1650504231255,"user_tz":240,"elapsed":300,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"24cc5932-8517-4e61-b307-d28ea8be6f32"},"execution_count":153,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         6\n","           1       0.50      1.00      0.67         2\n","           2       0.75      1.00      0.86         6\n","           3       0.75      0.75      0.75         4\n","           4       1.00      0.88      0.93         8\n","           5       1.00      0.90      0.95        10\n","           6       0.90      0.90      0.90        10\n","           7       1.00      0.78      0.88         9\n","           8       1.00      1.00      1.00         5\n","           9       1.00      1.00      1.00         4\n","\n","    accuracy                           0.91        64\n","   macro avg       0.89      0.92      0.89        64\n","weighted avg       0.93      0.91      0.91        64\n","\n"]}]},{"cell_type":"code","metadata":{"executionInfo":{"status":"ok","timestamp":1650504238555,"user_tz":240,"elapsed":263,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"id":"NXLVcVT09CwR"},"source":["# Entrene aquí su red.\n","model = nn.Sequential(nn.Linear(784, 256),\n","                      nn.ReLU(),\n","                      nn.Linear(256, 128),\n","                      nn.ReLU(),\n","                      nn.Linear(128, 64),\n","                      nn.ReLU(),\n","                      nn.Linear(64, 10),\n","                      nn.LogSoftmax(dim=1))\n","\n","criterion = nn.NLLLoss()\n","optimizer = optim.SGD(model.parameters(), lr=3)\n"],"execution_count":155,"outputs":[]},{"cell_type":"code","source":["epochs = 10\n","for e in range(epochs):\n","    print(f\"epoch {e + 1}\")\n","    running_loss = 0\n","    \n","    for images, labels in trainloader:\n","        optimizer.zero_grad()\n","        # Genere un vector de 784 caracteristicas. \n","        images = images.view(images.shape[0], -1)\n","        output = model(images)\n","        loss = criterion(output, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss\n","        #Realice el forward\n","        # Calcule el loss.\n","        # Realice el backward()\n","        # Optimice\n","        # Acumule el loss.\n","    print(f\"loss promedio de la epoch {e + 1}: {running_loss/len(trainloader)}\")\n","    print(\"========================\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650504374255,"user_tz":240,"elapsed":135339,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"9ed32dc1-0b30-47d7-fc59-90d91bb677e0","id":"y9Lns4w69CwT"},"execution_count":156,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 1\n","loss promedio de la epoch 1: nan\n","========================\n","epoch 2\n","loss promedio de la epoch 2: nan\n","========================\n","epoch 3\n","loss promedio de la epoch 3: nan\n","========================\n","epoch 4\n","loss promedio de la epoch 4: nan\n","========================\n","epoch 5\n","loss promedio de la epoch 5: nan\n","========================\n","epoch 6\n","loss promedio de la epoch 6: nan\n","========================\n","epoch 7\n","loss promedio de la epoch 7: nan\n","========================\n","epoch 8\n","loss promedio de la epoch 8: nan\n","========================\n","epoch 9\n","loss promedio de la epoch 9: nan\n","========================\n","epoch 10\n","loss promedio de la epoch 10: nan\n","========================\n"]}]},{"cell_type":"code","source":["model[0].weight"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OKpCqHmm9GI_","executionInfo":{"status":"ok","timestamp":1650504374257,"user_tz":240,"elapsed":11,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"479f06c3-b70a-4e57-d40c-04fa12d911ce"},"execution_count":157,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[ 3.8072e-02,  4.9191e-02,  4.6810e-02,  ...,  3.6291e-02,\n","          4.5789e-02,  7.7335e-02],\n","        [ 2.4871e+00,  2.5232e+00,  2.4859e+00,  ...,  2.5258e+00,\n","          2.5017e+00,  2.4917e+00],\n","        [-2.0423e-02, -2.7355e-02,  7.1572e-03,  ...,  2.6936e-02,\n","          8.2099e-03, -1.3376e-02],\n","        ...,\n","        [        nan,         nan,         nan,  ...,         nan,\n","                 nan,         nan],\n","        [        nan,         nan,         nan,  ...,         nan,\n","                 nan,         nan],\n","        [-4.1635e-03,  4.6250e-02, -1.8951e-02,  ...,  2.3562e-02,\n","         -8.9472e-04, -1.7621e-02]], requires_grad=True)"]},"metadata":{},"execution_count":157}]},{"cell_type":"code","source":["img = images[0].view(1, 784)\n","# Aqui sirve apagar los gradientes para ser mas eficientes. \n","with torch.no_grad():\n","    logps = model(img) # Este es el modelo\n","\n","# La salida de la red son logaritmos de probabilidades (Por la función de perdida utilizada), \n","# tenemos que aplicar una exponencial para obtener probabilidades. \n","ps = torch.exp(logps)\n","view_classify(img.view(1, 28, 28), ps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"ch-CX0059wGS","executionInfo":{"status":"ok","timestamp":1650504374908,"user_tz":240,"elapsed":660,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"3872604a-02ea-4eb0-905a-ad4fab4831f3"},"execution_count":158,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x648 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["logps"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htl2N8Rp9zLQ","executionInfo":{"status":"ok","timestamp":1650504374909,"user_tz":240,"elapsed":13,"user":{"displayName":"SEBASTIAN ENRIQUE RODRIGUEZ ORTIZ","userId":"07613002149790340902"}},"outputId":"a88c7c3d-9f79-4b6e-824b-391bfef206eb"},"execution_count":159,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])"]},"metadata":{},"execution_count":159}]},{"cell_type":"code","source":[""],"metadata":{"id":"aPAqvnAIER90"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kSo9YGHIZDt4"},"source":["Ahora nuestra red puede predecir de mejor precisión los dígitos en nuestras imágenes."]},{"cell_type":"markdown","metadata":{"id":"p1ZhCvJ9qQXe"},"source":["<font color='green'>**Fin Actividad 4**</font>"]}]}