{"cells":[{"cell_type":"markdown","source":["# **Proyecto: Kafka y Spark Streaming (datos de wikipedia)**"],"metadata":{"id":"jkUwB3ezFZ_K","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97b2560b-0fff-4719-a3ee-498b5f5da8b1"}}},{"cell_type":"markdown","source":["Seguiremos usando los datos de wikichange para responder a lo sgte:\n","<li>Escriba una consulta que cuente y agrupe por el atributo bot del mensaje. Ejecute la consulta en forma iterativa y muestre como los resultados van cambiando.</li>\n","<li>Para lo anterior, active desde Colab el productor codificado en el notebook BD06-Kafka-Spark. Importante: los datos recibidos se estan almacenando en memoria principal del consumidor.</li>\n","<li>Escriba una consulta que muestre como va cambiando el conteo de bots pero usando ventanas deslizantes. Para la ventana de tiempo utilice el atributo change_timestamp del mensaje.</li>\n","<li>Proponga 3 consultas m√°s que permitan ver como los datos van cambiando en el tiempo.</li>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b7094a1-b66c-44d3-87ed-50fe4e87bfe9"},"id":"mdhd7YDkeGII"}},{"cell_type":"code","source":["!spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1 MyPythonScript.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BU91k_WiZM_8","executionInfo":{"status":"ok","timestamp":1653434856758,"user_tz":240,"elapsed":4671,"user":{"displayName":"MARIO ANTONIO CASTILLO MACHUCA","userId":"11911169784446403315"}},"outputId":"0f9db3ff-321c-46cc-88de-3fe7449f8239"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING: An illegal reflective access operation has occurred\n","WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.7/dist-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n","WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n",":: loading settings :: url = jar:file:/usr/local/lib/python3.7/dist-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n","Ivy Default Cache set to: /root/.ivy2/cache\n","The jars for the packages stored in: /root/.ivy2/jars\n","org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",":: resolving dependencies :: org.apache.spark#spark-submit-parent-36a2361a-313f-4985-93de-343c5669284d;1.0\n","\tconfs: [default]\n","\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.1 in central\n","\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.1 in central\n","\tfound org.apache.kafka#kafka-clients;2.4.1 in central\n","\tfound com.github.luben#zstd-jni;1.4.4-3 in central\n","\tfound org.lz4#lz4-java;1.7.1 in central\n","\tfound org.xerial.snappy#snappy-java;1.1.7.5 in central\n","\tfound org.slf4j#slf4j-api;1.7.30 in central\n","\tfound org.spark-project.spark#unused;1.0.0 in central\n","\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",":: resolution report :: resolve 959ms :: artifacts dl 43ms\n","\t:: modules in use:\n","\tcom.github.luben#zstd-jni;1.4.4-3 from central in [default]\n","\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n","\torg.apache.kafka#kafka-clients;2.4.1 from central in [default]\n","\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.0.1 from central in [default]\n","\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.1 from central in [default]\n","\torg.lz4#lz4-java;1.7.1 from central in [default]\n","\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n","\torg.spark-project.spark#unused;1.0.0 from central in [default]\n","\torg.xerial.snappy#snappy-java;1.1.7.5 from central in [default]\n","\t---------------------------------------------------------------------\n","\t|                  |            modules            ||   artifacts   |\n","\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n","\t---------------------------------------------------------------------\n","\t|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |\n","\t---------------------------------------------------------------------\n",":: retrieving :: org.apache.spark#spark-submit-parent-36a2361a-313f-4985-93de-343c5669284d\n","\tconfs: [default]\n","\t0 artifacts copied, 9 already retrieved (0kB/16ms)\n","22/05/24 23:27:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","python3: can't open file '/content/MyPythonScript.py': [Errno 2] No such file or directory\n","log4j:WARN No appenders could be found for logger (org.apache.spark.util.ShutdownHookManager).\n","log4j:WARN Please initialize the log4j system properly.\n","log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n"]}]},{"cell_type":"code","source":["!pip install pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LRpcNnIjMPXf","executionInfo":{"status":"ok","timestamp":1653434859646,"user_tz":240,"elapsed":2899,"user":{"displayName":"MARIO ANTONIO CASTILLO MACHUCA","userId":"11911169784446403315"}},"outputId":"662eba4f-44a8-4df4-dcd0-7e961824d530"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.1)\n","Requirement already satisfied: py4j==0.10.9.3 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.3)\n"]}]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import * \n","import pyspark.sql.functions as fn \n","from pyspark.sql.types import StringType\n","import time"],"metadata":{"id":"xF--dkudDaSj","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec219896-9603-441d-aa88-33062c5e410a"},"executionInfo":{"status":"ok","timestamp":1653434859647,"user_tz":240,"elapsed":21,"user":{"displayName":"MARIO ANTONIO CASTILLO MACHUCA","userId":"11911169784446403315"}}},"outputs":[],"execution_count":3},{"cell_type":"code","source":["sc = SparkContext('local')"],"metadata":{"id":"B2ETr-n8WdXK","executionInfo":{"status":"ok","timestamp":1653434865944,"user_tz":240,"elapsed":6317,"user":{"displayName":"MARIO ANTONIO CASTILLO MACHUCA","userId":"11911169784446403315"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["spark = SparkSession(sc)"],"metadata":{"id":"pK0oTr2qNukj","executionInfo":{"status":"ok","timestamp":1653434866345,"user_tz":240,"elapsed":414,"user":{"displayName":"MARIO ANTONIO CASTILLO MACHUCA","userId":"11911169784446403315"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["wikiStream = (spark\n","  .readStream\n","  .format(\"kafka\")\n","  .option(\"kafka.bootstrap.servers\",\"ec2-18-118-112-10.us-east-2.compute.amazonaws.com:9092\") # kafka server\n","  .option(\"subscribe\", \"wiki\") # topic\n","  .option(\"startingOffsets\", \"earliest\") # start from beginning \n","  .load())"],"metadata":{"id":"soTZZL9YDvt1","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"883ba54d-4d76-4807-a3fd-d6b4898056db"},"colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"status":"error","timestamp":1653434867775,"user_tz":240,"elapsed":1432,"user":{"displayName":"MARIO ANTONIO CASTILLO MACHUCA","userId":"11911169784446403315"}},"outputId":"9a39925b-f5e8-43be-e67f-c20eece8b4ea"},"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-1e6958093232>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kafka.bootstrap.servers\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ec2-18-118-112-10.us-east-2.compute.amazonaws.com:9092\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# kafka server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"subscribe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wiki\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# topic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"startingOffsets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"earliest\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# start from beginning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   .load())\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/streaming.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     def json(self, path, schema=None, primitivesAsString=None, prefersDecimal=None,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m:  Failed to find data source: kafka. Please deploy the application as per the deployment section of \"Structured Streaming + Kafka Integration Guide\".        "]}],"execution_count":6},{"cell_type":"code","source":["wikiStream"],"metadata":{"id":"H3uAPZjFE3xF","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4bb067a7-386f-4b4a-8522-33b1739d17f8"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["wikiStream.isStreaming"],"metadata":{"id":"dkx7ApzJjgff","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f0aba723-5fc0-4d81-b880-e16201d88abd"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from pyspark.sql.types import StringType\n","\n","# Convert binary to string key and value\n","wikiStream = (wikiStream\n","    .withColumn(\"key\", wikiStream[\"key\"].cast(StringType()))\n","    .withColumn(\"value\", wikiStream[\"value\"].cast(StringType())))"],"metadata":{"id":"nPCdxJTnFBNF","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0558080f-698b-4ac5-97c5-6733333413cf"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["wikiStream"],"metadata":{"id":"19hfGTgd0_oP","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3ad07d45-4a75-4d97-a1da-5091f8749441"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from pyspark.sql.functions import from_json\n","from pyspark.sql.types import StructType, StructField, BooleanType, LongType, IntegerType\n","\n","# Event data schema\n","schema_wiki = StructType(\n","    [StructField(\"$schema\",StringType(),True),\n","     StructField(\"bot\",BooleanType(),True),\n","     StructField(\"comment\",StringType(),True),\n","     StructField(\"id\",StringType(),True),\n","     StructField(\"length\",\n","                 StructType(\n","                     [StructField(\"new\",IntegerType(),True),\n","                      StructField(\"old\",IntegerType(),True)]),True),\n","     StructField(\"meta\",\n","                 StructType(\n","                     [StructField(\"domain\",StringType(),True),\n","                      StructField(\"dt\",StringType(),True),\n","                      StructField(\"id\",StringType(),True),\n","                      StructField(\"offset\",LongType(),True),\n","                      StructField(\"partition\",LongType(),True),\n","                      StructField(\"request_id\",StringType(),True),\n","                      StructField(\"stream\",StringType(),True),\n","                      StructField(\"topic\",StringType(),True),\n","                      StructField(\"uri\",StringType(),True)]),True),\n","     StructField(\"minor\",BooleanType(),True),\n","     StructField(\"namespace\",IntegerType(),True),\n","     StructField(\"parsedcomment\",StringType(),True),\n","     StructField(\"patrolled\",BooleanType(),True),\n","     StructField(\"revision\",\n","                 StructType(\n","                     [StructField(\"new\",IntegerType(),True),\n","                      StructField(\"old\",IntegerType(),True)]),True),\n","     StructField(\"server_name\",StringType(),True),\n","     StructField(\"server_script_path\",StringType(),True),\n","     StructField(\"server_url\",StringType(),True),\n","     StructField(\"timestamp\",StringType(),True),\n","     StructField(\"title\",StringType(),True),\n","     StructField(\"type\",StringType(),True),\n","     StructField(\"user\",StringType(),True),\n","     StructField(\"wiki\",StringType(),True)])\n","\n","# Create dataframe setting schema for event data\n","df_wiki = (wikiStream\n","           # Sets schema for event data\n","           .withColumn(\"value\", from_json(\"value\", schema_wiki))\n","          )"],"metadata":{"id":"3DjPFtbDFJiG","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9d2a00e0-26ee-4a8e-bdec-2ddd02ed1827"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["df_wiki"],"metadata":{"id":"33bkzPyNJd3R","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c13635a-c46b-4a05-80ea-bb81834ac663"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["df_wiki.isStreaming"],"metadata":{"id":"PL8PNws1j56O","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8690eb6d-631c-4e8e-9424-cd2a43f36d8b"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from pyspark.sql.functions import col, from_unixtime, to_date, to_timestamp\n","\n","# Transform into tabular \n","# Convert unix timestamp to timestamp\n","# Create partition column (change_timestamp_date)\n","df_wiki_formatted = (df_wiki.select(\n","    col(\"key\").alias(\"event_key\")\n","    ,col(\"topic\").alias(\"event_topic\")\n","    ,col(\"timestamp\").alias(\"event_timestamp\")\n","    ,col(\"value.$schema\").alias(\"schema\")\n","    ,\"value.bot\"\n","    ,\"value.comment\"\n","    ,\"value.id\"\n","    ,col(\"value.length.new\").alias(\"length_new\")\n","    ,col(\"value.length.old\").alias(\"length_old\")\n","    ,\"value.minor\"\n","    ,\"value.namespace\"\n","    ,\"value.parsedcomment\"\n","    ,\"value.patrolled\"\n","    ,col(\"value.revision.new\").alias(\"revision_new\")\n","    ,col(\"value.revision.old\").alias(\"revision_old\")\n","    ,\"value.server_name\"\n","    ,\"value.server_script_path\"\n","    ,\"value.server_url\"\n","    ,to_timestamp(from_unixtime(col(\"value.timestamp\"))).alias(\"change_timestamp\")\n","    ,to_date(from_unixtime(col(\"value.timestamp\"))).alias(\"change_timestamp_date\")\n","    ,\"value.title\"\n","    ,\"value.type\"\n","    ,\"value.user\"\n","    ,\"value.wiki\"\n","    ,col(\"value.meta.domain\").alias(\"meta_domain\")\n","    ,col(\"value.meta.dt\").alias(\"meta_dt\")\n","    ,col(\"value.meta.id\").alias(\"meta_id\")\n","    ,col(\"value.meta.offset\").alias(\"meta_offset\")\n","    ,col(\"value.meta.partition\").alias(\"meta_partition\")\n","    ,col(\"value.meta.request_id\").alias(\"meta_request_id\")\n","    ,col(\"value.meta.stream\").alias(\"meta_stream\")\n","    ,col(\"value.meta.topic\").alias(\"meta_topic\")\n","    ,col(\"value.meta.uri\").alias(\"meta_uri\")\n","))"],"metadata":{"id":"d0Hdjj10Fvev","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a252f1a2-6995-4875-9331-2aaa7891faef"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["df_wiki_formatted"],"metadata":{"id":"xUk6_lo_FyFZ","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f470f70a-0775-48d2-8520-905d8f9371f0"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["df_wiki_formatted.isStreaming"],"metadata":{"id":"8V07Qt16j_TK","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ecdadee-5f5e-4bd0-9345-e10f8de48b57"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["query = df_wiki_formatted.writeStream.format(\"memory\").queryName(\"wikiTable\").outputMode(\"append\").start()"],"metadata":{"id":"MThhzbGAEuIB","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea37679d-42cf-40b9-b359-8057a5800607"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["type(query)"],"metadata":{"id":"VzKgy4bTkq8F","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8a28d5af-3ac9-4e4e-8fbf-8271147630e1"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["print(query.name)"],"metadata":{"id":"0LoeTVnfmGMP","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eff9f1a7-ea8d-4375-ab16-8acda5e8b849"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["for x in range(10):\n","  DF = spark.sql(\"select event_topic,bot,user from wikiTable\")\n","  print(DF.show())\n","  time.sleep(1)"],"metadata":{"id":"xsGnckE0EuGw","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d6567f1e-30a1-49bd-9a13-452510bc5939"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["print(spark.streams.active)"],"metadata":{"id":"99j2kI1Jpy43","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"223cdda8-3c3e-4378-94c7-e6c3cedcc325"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["query.stop()"],"metadata":{"id":"xKhmiqMPGOii","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7a18a0c-6a7b-4e34-be3b-cde6d7f09b38"}},"outputs":[],"execution_count":null}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.10","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"BD07-Kafka-SparkStreaming-Proyecto.ipynb","provenance":[],"collapsed_sections":[]},"application/vnd.databricks.v1+notebook":{"notebookName":"BD07-Kafka-SparkStreaming-Proyecto","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3515461225148779}},"nbformat":4,"nbformat_minor":0}